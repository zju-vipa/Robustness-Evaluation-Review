# Robustness-Evaluation-Review ðŸŽ‰


## Survey
### Data Distribution Shift 
#### Adversarial Perturbation

| Work | Paper | Task | Resources | Year |
|---|---|---|---|---|
| L-BFGS | [*Intriguing properties of neural networks*](https://arxiv.org/abs/1312.6199) [[pdf]](https://arxiv.org/pdf/1312.6199) | Classification  | [[github(unofficial)]](https://github.com/AmineDiro/Adversarial-Attacks) |  2013 |
| FGSM | [*Explaining and Harnessing Adversarial Examples*](https://arxiv.org/abs/1412.6572) [[pdf]](https://arxiv.org/pdf/1412.6572) | Classification | [[github(unofficial)]](https://github.com/Harry24k/adversarial-attacks-pytorch) | 2014 |
| JSMA | [*The Limitations of Deep Learning in Adversarial Settings*](https://ieeexplore.ieee.org/abstract/document/7467366/) [[pdf]](https://arxiv.org/pdf/1511.07528) | Classification | [[github(unofficial)]](https://github.com/Harry24k/adversarial-attacks-pytorch) | 2016 |
| DeepFool | [*DeepFool: A Simple and Accurate Method to Fool Deep Neural Networks*]

#### Corruptions
#### Natural Distribution Shift

| Work | Paper | Resources | Year |
|---|---|---|---|
| CIFAR10.1 | [*Do CIFAR-10 Classifiers Generalize to CIFAR-10?*](https://arxiv.org/abs/1806.00451) [[pdf]](https://arxiv.org/pdf/1806.00451) | [[github]](https://github.com/modestyachts/CIFAR-10.1) | 2019 |
| ImageNetV2 |  [*Do ImageNet Classifiers Generalize to ImageNet?*](http://proceedings.mlr.press/v97/recht19a.html) [[pdf]](http://proceedings.mlr.press/v97/recht19a/recht19a.pdf) | [[github]](https://github.com/modestyachts/ImageNetV2) | 2019 | 
| ObjectNet|  [*ObjectNet: A large-scale bias-controlled dataset for pushing the limits of object recognition models*](https://proceedings.neurips.cc/paper_files/paper/2019/hash/97af07a14cacba681feacf3012730892-Abstract.html) [[pdf]](https://proceedings.neurips.cc/paper_files/paper/2019/file/97af07a14cacba681feacf3012730892-Paper.pdf) | [[official site]](https://objectnet.dev/) | 2019 |
| ImageNet-A, ImageNet-O |   [*Natural Adversarial Examples*](https://openaccess.thecvf.com/content/CVPR2021/html/Hendrycks_Natural_Adversarial_Examples_CVPR_2021_paper.html) [[pdf]](https://openaccess.thecvf.com/content/CVPR2021/papers/Hendrycks_Natural_Adversarial_Examples_CVPR_2021_paper.pdf) | [[github]](https://github.com/hendrycks/natural-adv-examples) | 2021 |
| ImageNet-Vid-Robust, YTBB-Robust |  [*Do Image Classifiers Generalize Across Time?*](http://openaccess.thecvf.com/content/ICCV2021/html/Shankar_Do_Image_Classifiers_Generalize_Across_Time_ICCV_2021_paper.html) [[pdf]](https://openaccess.thecvf.com/content/ICCV2021/papers/Shankar_Do_Image_Classifiers_Generalize_Across_Time_ICCV_2021_paper.pdf) | [[download link]](https://do-imagenet-classifiers-generalize-across-time.s3-us-west-2.amazonaws.com/imagenet_vid_ytbb_robust.tar.gz)  | 2021 |
| ImageNet-R |  [*The Many Faces of Robustness: A Critical Analysis of Out-of-Distribution Generalization*](http://openaccess.thecvf.com/content/ICCV2021/html/Hendrycks_The_Many_Faces_of_Robustness_A_Critical_Analysis_of_Out-of-Distribution_ICCV_2021_paper.html) [[pdf]](https://openaccess.thecvf.com/content/ICCV2021/papers/Hendrycks_The_Many_Faces_of_Robustness_A_Critical_Analysis_of_Out-of-Distribution_ICCV_2021_paper.pdf) | [[github]](https://github.com/hendrycks/imagenet-r) | 2021 |
| COCO-O |  [*COCO-O: A Benchmark for Object Detectors under Natural Distribution Shifts*](http://openaccess.thecvf.com/content/ICCV2023/html/Mao_COCO-O_A_Benchmark_for_Object_Detectors_under_Natural_Distribution_Shifts_ICCV_2023_paper.html) [[pdf]](https://openaccess.thecvf.com/content/ICCV2023/papers/Mao_COCO-O_A_Benchmark_for_Object_Detectors_under_Natural_Distribution_Shifts_ICCV_2023_paper.pdf) | [[github]](https://github.com/alibaba/easyrobust/tree/main/benchmarks/coco_o) | 2023 |




## Protocal
